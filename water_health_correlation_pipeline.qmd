---
title: "Assessing Key Indicators Through Random Forest Variable Importance Analysis"
format: html
editor: visual
---

## Data Cleaning / Pre-processing steps

```{r}
library(dplyr)
library(ggplot2)
library(tidyverse)
library(ggthemes)

dat <- read_csv("data/water_health_indicators.csv")

# data cleaning steps
dat_clean <- dat %>%
  filter(subgroup %in% "Rural") %>% #this selection is arbitrary results are representative of population 
  mutate(date = as.numeric(date)) %>% 
  filter(date < 2019) %>% 
  select(-source, -dimension, -se, -ci_lb, -ci_ub, -flag, -iso3, -favourable_indicator, -update, -dataset_id, -indicator_abbr, -indicator_scale,-ordered_dimension, -subgroup_order, -reference_subgroup, -wbincome2024, -estimate, -population) %>%
  mutate(year = as.character(date)) %>%
  unite("country_year", setting, year, sep = "_") %>%
  pivot_wider(
    names_from = indicator_name,
    values_from = setting_average
  ) %>% 
  select(1:16)

#read in fetal mortality rate data
fetal_mortality_rate_dat <- read_csv("data/fetal_mortality.csv")

#fetal mortality rate data cleaning 
fmr_dat_clean <- fetal_mortality_rate_dat %>%
  filter(date > 1999) %>%
  select(setting, date, dimension, setting_average, population) %>% 
  mutate(year = as.character(date)) %>% 
  unite("country_year", setting, year, sep = "_") %>%
  filter(dimension %in% c("Sex")) 

#joining the data with some final cleaning steps
final_dataset <- dat_clean %>%
  full_join(fmr_dat_clean, by = c("country_year", "date")) %>% 
  rename("fetal_mortality_country_average" = "setting_average") %>% 
  select(-dimension, -population) %>% 
  drop_na() %>% 
  unique()
  
#composing this into a final data set for further analysis
write_csv(final_dataset, "data/country_indicators_and_fmr.csv")

```

```{python}
'''
This calculates the Pearson correlation coefficients, quantifying
the relationship between water/health indicators and under-5 mortality
Psuedocode:
1)  Get scrubbed data into dataframe
2)  Drop extra non-indicator data
3)  Calculate the Pearson correlation coefficients for between each indicator and
    the under-5 mortality rate
'''

import numpy as np
import pandas as pd
  
def calculate_pearson_correlation_coefficient(df):
  '''
  Goal: Calculate the Pearson correlation coefficient between two arrays!
  https://en.wikipedia.org/wiki/Pearson_correlation_coefficient
  
  Input Variables:
    df: Our dataframe that contains water and health indicators as percentages
    of the population as well as an appended under-5 mortality column as deaths
    per 1000.
  
  Output Variables:
    pearson_correlation_matrix: A matrix containing the calculated Pearson correlation coefficient
    between each indicator. The output measures both strength and direction of the 
    relationship between variables on a scale between -1 and 1.

    u5_pearson_correlation_coefficients: A single column with just the correlation between indicators
    and under-5(u5) mortality
  '''
  # Calculate the coeffiecients automatically using pandas methods
  # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html
  pearson_correlation_matrix = df.corr(method='pearson')

  # Isolate the under-5 mortality and indicator coefficients from the matrix
  u5_pearson_correlation_coefficients = pearson_correlation_matrix['fetal_mortality_country_avergage']
  
  # Drop the u5 correlation with itself
  u5_pearson_correlation_coefficients.drop('fetal_mortality_country_average', errors='ignore')

  return u5_pearson_correlation_coefficients

def import_data(file):
  '''
  Goal: Take scrubbed data as a .csv and convert to pandas dataframe
  '''
  df = pd.read_csv(file)

  return df

def main():
  # 1) Import data
  df = import_data("data/country_indicators_and_fmr.csv")

  # 2) Drop non-indicator columns
  df_indicators = df.drop(columns =['country_year','date','subgroup','whoreg6'])
  # Convert string data to float64
  df_indicators_numeric = df.indicators.astype(np.float64)

  # 3) Get the Pearson correlation coefficients between under-5 mortality and each indicator
  u5_pearson_correlation_coefficients = calculate_pearson_correlation_coefficient(df_indicators)
  # Sort in descending order to get the strongest indicators
  with open('results/pearson_correlation_results.txt', 'w') as file
    file.write(u5_pearson_correlation_coefficients.sort_values(ascending=False, key=abs))
  print(u5_pearson_correlation_coefficients.sort_values(ascending=False, key=abs))

if __name__ == "__main__":
  main()
```

# Building a Random Forest Model and Evaluating Variable Importance

```{r}
# building random forest modeling 

# set the seed to have reproducibility
set.seed(253)

#loading in nessecary packages 
library(tidyverse)
library(tidymodels)
library(rpart)        # for building trees
library(rpart.plot)   # for plotting trees
library(randomForest) # for bagging & forests
library(infer) 
library(vip)


#resolves package conflicts by preferring tidymodels functions
tidymodels_prefer()


# STEP 1: Model Specification
rf_spec <- rand_forest()  %>%
  set_mode("regression") %>%
  set_engine(engine = "ranger") %>% 
  set_args(
    mtry = NULL,
    trees = 500,
    min_n = 2,
    probability = FALSE, # give classifications, not probability calculations
    importance = "impurity" # use Gini index to measure variable importance
  )

# STEP 2: Build the forest model
ensemble_model <- rf_spec %>% 
  fit(fetal_mortality_country_average ~ 
      `Population using basic sanitation services (%)` + 
      `Population using limited sanitation services (%)` + 
      `Population practising open defecation (%)` + 
      `Population using basic drinking water services (%)` + 
      `Population using limited drinking water services (%)` + 
      `Population using surface water (%)` + 
      `Population using basic hygiene services (%)` + 
      `Population using limited hygiene services (%)` + 
      `Population with no hygiene services (%)`, 
      data = final_dataset)

#plucking variable importance 
ensemble_model %>%
  extract_fit_engine() %>%
  pluck("variable.importance") %>% 
  sort(decreasing = TRUE)

#graphing variable importance
ensemble_model %>% 
  vip(geom = "point", num_features = 9) +
  labs(title = "Understanding Indicator Importance",
       x = "Indicator",
       y = "Importance Score") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

#graphing variable importance (but, in a bar graph)
vip_plot <- ensemble_model %>% 
  vip(geom = "col", 
      num_feature = 9, 
      aesthetics = list(color = "black", fill = "#eae2d7")) +
  labs(title = "Understanding Indicator Importance",
       y = "Importance Score",
       x = "Indicator") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

ggsave(filename = "vip_plot.png", path = "figures", plot = vip_plot, width = 9, height = 6, dpi = 300)



#printing model metrics for evaluation

ensemble_model

library(yardstick)

predictions <- predict(ensemble_model, final_dataset) %>% bind_cols(final_dataset)

predictions %>% 
  metrics(truth = fetal_mortality_country_average, estimate = .pred) %>% 
  print()

```

# 
```{python}
"""rural_indicaters1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BiPcVOLQTFxIIqVelaE5tnwGn6_HcAAD
"""
"""Rural WASH Indicators & Fetal Mortality - Data Analysis

This notebook explores the relationship between WASH (Water, Sanitation, and Hygiene) indicators 
and fetal mortality rates in rural regions across countries.

Key steps performed:
1. Dataset import & preview
2. Column checks & renaming for clarity
3. Merging WASH & fetal mortality datasets
4. Cleaning & preprocessing
5. Exploratory scatter plot: sanitation vs fetal mortality
6. Random Forest model to evaluate importance of WASH factors
7. Feature importance visualization""" 


# -------------------------------
# Import Libraries
# -------------------------------
   
from google.colab import files
uploaded = files.upload()

import pandas as pd
import matplotlib.pyplot as plt
# -------------------------------
# Upload & Load Datasets
# -------------------------------

# Load CSVs (replace names if needed)
wash = pd.read_csv("rural_indicators.csv")
fetal = pd.read_csv("fetal_mortality.csv")

print("WASH Data Preview:")
display(wash.head())

print("\nFetal Mortality Data Preview:")
display(fetal.head())

 #  Inspect Available Columns)
 
print("\nColumns in WASH data:", wash.columns.tolist())
print("\nColumns in Fetal data:", fetal.columns.tolist())

df = pd.merge(wash, fetal, on=["country", "year"], how="inner")
df.head()

print("WASH columns:")
print(wash.columns.tolist())

print("\nFetal Mortality columns:")
print(fetal.columns.tolist())

# Split "country_year" into two columns: country & year
wash[['country', 'year']] = wash['country_year'].str.split('_', n=1, expand=True)

# Convert year column to numeric (just in case)
wash['year'] = pd.to_numeric(wash['year'], errors='coerce')

fetal['year'] = pd.to_numeric(fetal['date'], errors='coerce')

# ✅ Preprocessing & Merging

df = pd.merge(
    wash, fetal,
    on=['subgroup','year'],
    how='inner'
)

df.head()

df = df.rename(columns={
    'Population using basic sanitation services (%)': 'basic_sanitation',
    'estimate': 'fetal_mortality_rate'
})

import matplotlib.pyplot as plt

plt.figure(figsize=(6,4))
plt.scatter(df['basic_sanitation'], df['fetal_mortality_rate'])
plt.xlabel("Basic Sanitation Access (%)")
plt.ylabel("Fetal Mortality Rate")
plt.title("Sanitation Access vs. Fetal Mortality")
plt.show()

df.shape
df.head()

print(df.columns)
df[['basic_sanitation', 'fetal_mortality_rate']].describe()

df[['basic_sanitation', 'fetal_mortality_rate']].isna().sum()

print(df['basic_sanitation'].unique()[:10])
print(df['fetal_mortality_rate'].unique()[:10])

for col in wash.columns:
    print(col)

Population using basic sanitation services (%)

wash = wash.rename(columns={
    'Population using basic sanitation services (%)': 'basic_sanitation',
    'fetal_mortality_country_avergage': 'fetal_mortality_rate'
})

wash_clean = wash.dropna(subset=['basic_sanitation','fetal_mortality_rate'])

import matplotlib.pyplot as plt

plt.figure(figsize=(6,4))
plt.scatter(wash_clean['basic_sanitation'], wash_clean['fetal_mortality_rate'])
plt.xlabel("Basic Sanitation Access (%)")
plt.ylabel("Fetal Mortality Rate")
plt.title("Sanitation Access vs. Fetal Mortality")
plt.show()

import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns

# Filter rural data
rural = wash[wash['subgroup'].str.contains('Rural', case=False, na=False)]

# Rename columns for clarity
rural = rural.rename(columns={
    "Population using basic sanitation services (%)": "basic_sanitation",
    "Population using limited sanitation services (%)": "limited_sanitation",
    "Population practising open defecation (%)": "open_defecation",
    "Population using basic drinking water services (%)": "basic_water",
    "Population using limited drinking water services (%)": "limited_water",
    "Population using unimproved drinking water services (%)": "unimproved_water",
    "Population using basic hygiene services (%)": "basic_hygiene",
    "Population using limited hygiene services (%)": "limited_hygiene",
    "Population with no hygiene services (%)": "no_hygiene"
})

# Select features + target
features = [
    "basic_sanitation", "limited_sanitation", "open_defecation",
    "basic_water", "limited_water", "unimproved_water",
    "basic_hygiene", "limited_hygiene", "no_hygiene"
]

X = rural[features]
y = rural["fetal_mortality_country_average"]

# Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Random Forest Model
rf = RandomForestRegressor(n_estimators=500, random_state=42)
rf.fit(X_train, y_train)

# Feature Importance
importances = pd.Series(rf.feature_importances_, index=features).sort_values(ascending=False)

#  Exploratory Analysis
# Scatter plot: sanitation vs fetal mortality

# Plot
plt.figure(figsize=(8,5))
sns.barplot(x=importances.values, y=importances.index)
plt.title("WASH Factors Impacting Infant/Fetal Mortality (Rural Areas)")
plt.xlabel("Feature Importance")
plt.ylabel("WASH Factor")
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
import numpy as np

# Columns
hygiene_col = 'Population using basic hygiene services (%)'
mortality_col = 'fetal_mortality_country_avergage'

# Remove missing values
df_clean = df[[hygiene_col, mortality_col]].dropna()

# X and y for model
X = df_clean[[hygiene_col]]  # independent variable
y = df_clean[mortality_col]  # target

# Model
model = LinearRegression()
model.fit(X, y)

# Predictions
y_pred = model.predict(X)

# Plot
plt.figure(figsize=(8,5))
plt.scatter(X, y, color='pink', label='Data points')
plt.plot(X, y_pred, label='Regression Line')  # default color
plt.xlabel('Basic Hygiene Services (%)')
plt.ylabel('Fetal Mortality Rate')
plt.title('Linear Regression: Hygiene vs Fetal Mortality')
plt.grid(True)
plt.legend()
plt.show()

# Coefficient and intercept
print("Slope (effect):", model.coef_[0])
print("Intercept:", model.intercept_)
print("R² Score:", model.score(X, y))
```